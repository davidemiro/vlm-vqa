model_deployments:
  - name: vlm-vqa
    model_name: vlm-vqa
    tokenizer_name: google/gemma-2b
    max_sequence_length: 20
    model_max_length: 20
    client_spec:
      class_name: "helm.client.VLMClient"
      args:
        pretrained_model_name_or_path: mirodavide/vlm-vqa